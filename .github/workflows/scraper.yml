name: Scrape and Insert Medicines

on:
  schedule:
    - cron: '0 */12 * * *'
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Deno (versión estable compatible con smtp@0.7.0 y GitHub Actions)
        uses: denoland/setup-deno@v1
        with:
          deno-version: "1.43.6" # ⚠️ No usar Deno 2.x ya que rompe smtp@0.7.0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Python dependencies
        run: |
          pip install beautifulsoup4 playwright httpx
          playwright install

      - name: Create .env file
        run: |
          cat > .env << 'EOF'
          MONGODB_URI=${{ secrets.MONGODB_URI }}
          JWT_SECRET=${{ secrets.JWT_SECRET }}
          GMAIL_USER=${{ secrets.GMAIL_USER }}
          GMAIL_PASS=${{ secrets.GMAIL_PASS }}
          BASE_URL=${{ secrets.BASE_URL }}
          EOF
          echo "✅ .env file created"
          echo "Checking .env file format:"
          cat .env | sed 's/=.*/=***/'
        working-directory: MediSearch

      - name: Debug paths
        run: |
          echo "Current directory: $(pwd)"
          echo "Directory contents:"
          ls -la
          echo "deno.json exists: $(test -f deno.json && echo 'Yes' || echo 'No')"
          echo "scraping_tasks directory exists: $(test -d scraping_tasks && echo 'Yes' || echo 'No')"
          if [ -f deno.json ]; then
            echo "deno.json content:"
            cat deno.json
          fi
        working-directory: MediSearch

      - name: Extract URLs (if URL extractor exists)
        run: |
          if [ -f "url_extractor/extract_urls.py" ]; then
            echo "🔍 Running URL extractor..."
            python3 url_extractor/extract_urls.py
          else
            echo "📁 Creating empty URL files for scrapers..."
            mkdir -p url_extractor/extracted_urls
            echo '{}' > url_extractor/extracted_urls/ahumada_urls.json
            echo '{}' > url_extractor/extracted_urls/cruzverde_urls.json
            echo '{}' > url_extractor/extracted_urls/salcobrand_urls.json
          fi
        working-directory: MediSearch

      - name: Run scrape-and-insert
        run: deno task scrape-and-insert
        working-directory: MediSearch

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-logs
          path: MediSearch/logs/
