name: Scrape Medicines

on:
  schedule:
    - cron: '0 3 * * *' # Todos los dÃ­as a las 03:00 UTC (00:00 Chile)
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ”„ Checkout repository
        uses: actions/checkout@v3

      - name: ğŸ¦• Set up Deno 1.43.6
        uses: denoland/setup-deno@v1
        with:
          deno-version: "1.43.6"

      - name: ğŸ§ª Confirm Deno version
        run: deno --version

      - name: ğŸ Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: ğŸ“¦ Install Python dependencies
        run: |
          pip install beautifulsoup4 playwright httpx
          playwright install

      - name: ğŸ—‚ï¸ Create .env file
        run: |
          cat > .env << 'EOF'
          MONGODB_URI=${{ secrets.MONGODB_URI }}
          JWT_SECRET=${{ secrets.JWT_SECRET }}
          GMAIL_USER=${{ secrets.GMAIL_USER }}
          GMAIL_PASS=${{ secrets.GMAIL_PASS }}
          BASE_URL=${{ secrets.BASE_URL }}
          EOF
          echo "âœ… .env file created:"
          cat .env | sed 's/=.*/=***/'
        working-directory: MediSearch

      - name: ğŸ“ Debug directory structure
        run: |
          echo "Current directory: $(pwd)"
          ls -la
          echo "ğŸ” Checking important files:"
          test -f deno.json && echo "âœ… deno.json found"
          test -f deno.lock && echo "âœ… deno.lock found"
          test -d scraping_tasks && echo "âœ… scraping_tasks directory found"
        working-directory: MediSearch

      - name: ğŸ”— Extract URLs (if extractor exists)
        run: |
          if [ -f "url_extractor/extract_urls.py" ]; then
            echo "ğŸ” Running URL extractor..."
            python3 url_extractor/extract_urls.py
          else
            echo "ğŸ“ Creating empty URL files for scrapers..."
            mkdir -p url_extractor/extracted_urls
            echo '{}' > url_extractor/extracted_urls/ahumada_urls.json
            echo '{}' > url_extractor/extracted_urls/cruzverde_urls.json
            echo '{}' > url_extractor/extracted_urls/salcobrand_urls.json
          fi
        working-directory: MediSearch

      - name: ğŸ› ï¸ Ensure product_updates folder exists
        run: mkdir -p Scrapers_MediSearch/product_updates
        working-directory: MediSearch

      - name: ğŸš€ Run scrapers only (no DB insert)
        run: deno run --allow-read --allow-run --allow-env --allow-write --allow-net scraping_tasks/runScrapersOnly.ts
        working-directory: MediSearch

      - name: ğŸ“¤ Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-logs
          path: MediSearch/logs/
